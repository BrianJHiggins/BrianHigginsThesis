{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15a80a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Description\n",
    "This notebook takes as input 'Transcripts_Questions_Answers_Test_cleaned_7.csv' and so on\n",
    "the file contains the plain text questions and answers extracted \n",
    "from Earnings Conference Call transcripts.\n",
    "The file is input to the FinBERT model. \n",
    "output file: 'earnings_calls_Kaggle_Test_q_a.csv'  The output consists of the input returned with\n",
    "each question and answer (row) given sentiment classification scores. Each Q and A can be inspected to \n",
    "check the classification given if required.\n",
    "processing time is ~ 6 minutes per input file using Kaggle with GPU P100 accelerator.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561e13ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57989e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {0:'positive', 1:'negative', 2:'neutral'}\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('ProsusAI/finbert')\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('ProsusAI/finbert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb479f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(text):\n",
    "    txt = text\n",
    "    tokens = tokenizer.encode_plus(txt, add_special_tokens=False)\n",
    "    input_ids, token_type_ids, attention_mask = tokens['input_ids'], tokens['token_type_ids'], tokens['attention_mask']\n",
    "    total_len = len(tokens['input_ids'])\n",
    "    return input_ids, attention_mask, total_len\n",
    "    tokens.keys()\n",
    "# tokens.keys()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150aca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text_to_window_size_and_predict_proba(input_ids, attention_mask, total_len):\n",
    "    \"\"\"\n",
    "    This function splits the given input text into chunks of a specified window length, \n",
    "    applies transformer model to each chunk and computes probabilities of each class for each chunk. \n",
    "    The computed probabilities are then appended to a list.\n",
    "\n",
    "    Args:\n",
    "        input_ids (List[int]): List of token ids representing the input text.\n",
    "        attention_mask (List[int]): List of attention masks corresponding to input_ids.\n",
    "        total_len (int): Total length of the input_ids.\n",
    "\n",
    "    Returns:\n",
    "        proba_list (List[torch.Tensor]): List of probability tensors for each chunk.\n",
    "    \"\"\"\n",
    "    proba_list = []\n",
    "    \n",
    "    start = 0\n",
    "    window_length = 510\n",
    "    \n",
    "    loop = True\n",
    "    \n",
    "    while loop:\n",
    "        end = start  + window_length\n",
    "        # If the end index exceeds total length, set the flag to False and adjust the end index\n",
    "        if end >= total_len:\n",
    "            loop = False\n",
    "            end = total_len\n",
    "\n",
    "        # 1 => Define the text chunk\n",
    "        input_ids_chunk = input_ids[start : end]\n",
    "        attention_mask_chunk = attention_mask[start : end]\n",
    "        \n",
    "        # 2 => Append [CLS] and [SEP]\n",
    "        input_ids_chunk = [101] + input_ids_chunk + [102]\n",
    "        attention_mask_chunk = [1] + attention_mask_chunk + [1]\n",
    "        \n",
    "        #3 Convert regular python list to Pytorch Tensor\n",
    "        input_dict = {\n",
    "            'input_ids' : torch.Tensor([input_ids_chunk]).long(),\n",
    "            'attention_mask' : torch.Tensor([attention_mask_chunk]).int()\n",
    "        }\n",
    "        \n",
    "        outputs = model(**input_dict)\n",
    "        probabilities = torch.nn.functional.softmax(outputs[0], dim = -1)\n",
    "        proba_list.append(probabilities)\n",
    "        start = end\n",
    "        \n",
    "    return proba_list\n",
    "    \n",
    "    \n",
    "\n",
    "# proba_list = chunk_text_to_window_size_and_predict_proba(input_ids, attention_mask, total_len)\n",
    "# print(\"This is the 'proba' list:\", proba_list)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59efe04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_from_proba(proba_list):\n",
    "    \"\"\"\n",
    "    This function computes the mean probabilities of class predictions over all the chunks.\n",
    "\n",
    "    Args:\n",
    "        proba_list (List[torch.Tensor]): List of probability tensors for each chunk.\n",
    "\n",
    "    Returns:\n",
    "        mean (torch.Tensor): Mean of the probabilities across all chunks.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensures that gradients are not computed, saving memory\n",
    "    with torch.no_grad():\n",
    "        # Stack the list of tensors into a single tensor\n",
    "        stacks = torch.stack(proba_list)\n",
    "\n",
    "        # Resize the tensor to match the dimensions needed for mean computation\n",
    "        stacks = stacks.resize(stacks.shape[0], stacks.shape[2])\n",
    "        # print(\"This is 'stacks':\", stacks) #BH Tue 16Apr 00.27\n",
    "\n",
    "        # Compute the mean along the zeroth dimension (i.e., the chunk dimension)\n",
    "        mean = stacks.mean(dim = 0)\n",
    "        \n",
    "    return mean\n",
    "\n",
    "# mean = get_mean_from_proba(proba_list)\n",
    "# tensor([0.0767, 0.1188, 0.8045])\n",
    "\n",
    "# torch.argmax(mean).item()\n",
    "# mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103dd6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = './earnings_calls_Kaggle_Test_q_a.csv'\n",
    "\n",
    "\n",
    "# Note Row 2516 (Index 2515) - had to remove inverted commas: M-Real said there are ` no grounds ' for the rumors , which ` have been circulating in the market for some months . '\n",
    "\n",
    "\n",
    "# df = pd.read_csv('/kaggle/input/d/bjhths/transcripts-questions-and-answers-test-cleaned-csv/Transcripts_Questions_and_Answers_Test_cleaned.csv',encoding='latin1')\n",
    "df = pd.read_csv('/kaggle/input/transcripts-questions-answers-test-cleaned-7-csv/Transcripts_Questions_Answers_Test_cleaned_7.csv',encoding='latin1')\n",
    "\n",
    "with open(output_filename, 'a', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "   \n",
    "    csv_writer.writerow(['ID','Company_AName','Ticker', 'Text', 'Call_Section', 'Transcript_Text', 'sentiment','count of +ve', 'count of -ve', 'count of neutral'])\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for i, row in df.iterrows():\n",
    "        # Extract relevant information from the current row\n",
    "        ID = row['ID']\n",
    "        Company_AName = row['Company_AName']\n",
    "        Ticker = row['Ticker']\n",
    "        Text = row['Text']\n",
    "        Call_Section = row['Call_Section']\n",
    "        Transcript_Text = row['Transcript_Text']\n",
    "        # sentiment = row['sentiment']\n",
    "\n",
    "        # Perform sentiment analysis on the text to get FinBERT sentiment\n",
    "        # input_ids, attention_mask, total_len = text_processing(text)\n",
    "        \n",
    "        # BH 11Apr2024 15.39:- \n",
    "        input_ids, attention_mask, total_len = text_processing(Transcript_Text)\n",
    "        \n",
    "        proba_list = chunk_text_to_window_size_and_predict_proba(input_ids, attention_mask, total_len)\n",
    "        mean = get_mean_from_proba(proba_list)\n",
    "        result_class = classes[torch.argmax(mean).item()]\n",
    "        # print(\"This is the 'proba_list':\",proba_list) # BH Tue 16Apr 20.08\n",
    "        # Count of probability classes per line.\n",
    "        \n",
    "        # Initialize counters\n",
    "        count_positive = 0\n",
    "        count_negative = 0\n",
    "        count_neutral = 0\n",
    "        \n",
    "        # Count the occurrences of each class\n",
    "        for prob in proba_list:\n",
    "            pred_class = torch.argmax(prob).item()\n",
    "            if pred_class == 0:\n",
    "                count_positive += 1\n",
    "            elif pred_class == 1:\n",
    "                count_negative += 1\n",
    "            elif pred_class == 2:\n",
    "                count_neutral += 1\n",
    "\n",
    "        # Write the processed row to the output CSV file\n",
    "        csv_writer.writerow([ID, Company_AName, Ticker, Text, Call_Section, Transcript_Text, result_class, count_positive, count_negative, count_neutral]) \n",
    "\n",
    "        # Write the processed row to the output CSV file\n",
    "        # csv_writer.writerow([phrase_id, sentiment, text, result_class])\n",
    "        \n",
    "        # BH 11Apr2024 15.39:- \n",
    "        # Write the processed row to the output CSV file\n",
    "        # csv_writer.writerow([ID, Company_AName, Ticker, Text, Call_Section, Transcript_Text, result_class])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
