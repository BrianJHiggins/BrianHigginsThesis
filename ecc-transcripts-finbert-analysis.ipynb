{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8933257,"sourceType":"datasetVersion","datasetId":5374278}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nDescription\nThis notebook takes as input 'Transcripts_Questions_Answers_Test_cleaned_7.csv' \nthe file contains the plain text questions and answers extracted \nfrom Earnings Conference Call transcripts.\nThe file is input to the FinBERT model. \noutput file: 'earnings_calls_Kaggle_Test_q_a.csv'  The output consists of the input returned with\neach question and answer (row) given sentiment classification scores. Each Q and A can be inspected to \ncheck the classification given if required.\nprocessing time is ~ 6 minutes per input file using Kaggle with GPU P100 accelerator.\n\n\"\"\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import BertForSequenceClassification, BertTokenizer\nimport torch\nimport pandas as pd\nimport csv","metadata":{"execution":{"iopub.status.busy":"2024-07-26T14:40:29.573046Z","iopub.execute_input":"2024-07-26T14:40:29.573405Z","iopub.status.idle":"2024-07-26T14:40:29.578112Z","shell.execute_reply.started":"2024-07-26T14:40:29.573378Z","shell.execute_reply":"2024-07-26T14:40:29.577021Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"\n\nclasses = {0:'positive', 1:'negative', 2:'neutral'}\n\ntokenizer = BertTokenizer.from_pretrained('ProsusAI/finbert')\n\nmodel = BertForSequenceClassification.from_pretrained('ProsusAI/finbert')","metadata":{"execution":{"iopub.status.busy":"2024-07-26T14:40:34.385456Z","iopub.execute_input":"2024-07-26T14:40:34.385867Z","iopub.status.idle":"2024-07-26T14:40:35.274747Z","shell.execute_reply.started":"2024-07-26T14:40:34.385834Z","shell.execute_reply":"2024-07-26T14:40:35.273683Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"\ndef text_processing(text):\n    txt = text\n    tokens = tokenizer.encode_plus(txt, add_special_tokens=False)\n    input_ids, token_type_ids, attention_mask = tokens['input_ids'], tokens['token_type_ids'], tokens['attention_mask']\n    total_len = len(tokens['input_ids'])\n    return input_ids, attention_mask, total_len\n    tokens.keys()\n# tokens.keys()    ","metadata":{"execution":{"iopub.status.busy":"2024-07-26T14:40:39.788840Z","iopub.execute_input":"2024-07-26T14:40:39.789203Z","iopub.status.idle":"2024-07-26T14:40:39.794875Z","shell.execute_reply.started":"2024-07-26T14:40:39.789175Z","shell.execute_reply":"2024-07-26T14:40:39.793898Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"\ndef chunk_text_to_window_size_and_predict_proba(input_ids, attention_mask, total_len):\n    \"\"\"\n    This function splits the given input text into chunks of a specified window length, \n    applies transformer model to each chunk and computes probabilities of each class for each chunk. \n    The computed probabilities are then appended to a list.\n\n    Args:\n        input_ids (List[int]): List of token ids representing the input text.\n        attention_mask (List[int]): List of attention masks corresponding to input_ids.\n        total_len (int): Total length of the input_ids.\n\n    Returns:\n        proba_list (List[torch.Tensor]): List of probability tensors for each chunk.\n    \"\"\"\n    proba_list = []\n    \n    start = 0\n    window_length = 510\n    \n    loop = True\n    \n    while loop:\n        end = start  + window_length\n        # If the end index exceeds total length, set the flag to False and adjust the end index\n        if end >= total_len:\n            loop = False\n            end = total_len\n\n        # 1 => Define the text chunk\n        input_ids_chunk = input_ids[start : end]\n        attention_mask_chunk = attention_mask[start : end]\n        \n        # 2 => Append [CLS] and [SEP]\n        input_ids_chunk = [101] + input_ids_chunk + [102]\n        attention_mask_chunk = [1] + attention_mask_chunk + [1]\n        \n        #3 Convert regular python list to Pytorch Tensor\n        input_dict = {\n            'input_ids' : torch.Tensor([input_ids_chunk]).long(),\n            'attention_mask' : torch.Tensor([attention_mask_chunk]).int()\n        }\n        \n        outputs = model(**input_dict)\n        probabilities = torch.nn.functional.softmax(outputs[0], dim = -1)\n        proba_list.append(probabilities)\n        start = end\n        \n    return proba_list\n    \n    \n\n# proba_list = chunk_text_to_window_size_and_predict_proba(input_ids, attention_mask, total_len)\n# print(\"This is the 'proba' list:\", proba_list)\n   \n","metadata":{"execution":{"iopub.status.busy":"2024-07-26T14:40:49.809618Z","iopub.execute_input":"2024-07-26T14:40:49.810267Z","iopub.status.idle":"2024-07-26T14:40:49.819087Z","shell.execute_reply.started":"2024-07-26T14:40:49.810232Z","shell.execute_reply":"2024-07-26T14:40:49.818150Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"\n\ndef get_mean_from_proba(proba_list):\n    \"\"\"\n    This function computes the mean probabilities of class predictions over all the chunks.\n\n    Args:\n        proba_list (List[torch.Tensor]): List of probability tensors for each chunk.\n\n    Returns:\n        mean (torch.Tensor): Mean of the probabilities across all chunks.\n    \"\"\"\n    \n    # Ensures that gradients are not computed, saving memory\n    with torch.no_grad():\n        # Stack the list of tensors into a single tensor\n        stacks = torch.stack(proba_list)\n\n        # Resize the tensor to match the dimensions needed for mean computation\n        stacks = stacks.resize(stacks.shape[0], stacks.shape[2])\n        # print(\"This is 'stacks':\", stacks) #BH Tue 16Apr 00.27\n\n        # Compute the mean along the zeroth dimension (i.e., the chunk dimension)\n        mean = stacks.mean(dim = 0)\n        \n    return mean\n\n# mean = get_mean_from_proba(proba_list)\n# tensor([0.0767, 0.1188, 0.8045])\n\n# torch.argmax(mean).item()\n# mean\n","metadata":{"execution":{"iopub.status.busy":"2024-07-26T14:40:55.928943Z","iopub.execute_input":"2024-07-26T14:40:55.929312Z","iopub.status.idle":"2024-07-26T14:40:55.935598Z","shell.execute_reply.started":"2024-07-26T14:40:55.929282Z","shell.execute_reply":"2024-07-26T14:40:55.934588Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"\noutput_filename = './earnings_calls_Kaggle_Test_q_a.csv'\n\ndf = pd.read_csv('/kaggle/input/transcripts-questions-answers-test-cleaned-7-csv/Transcripts_Questions_Answers_Test_cleaned_7.csv',encoding='utf-8')\nwith open(output_filename, 'w', newline='', encoding = 'utf-8') as csvfile:\n    csv_writer = csv.writer(csvfile)\n   \n    csv_writer.writerow(['ID','Company_AName','Ticker', 'Text', 'Call_Section', 'Transcript_Text', 'sentiment','count of +ve', 'count of -ve', 'count of neutral'])\n\n    # Iterate over each row in the DataFrame\n    for i, row in df.iterrows():\n        # Extract relevant information from the current row\n        ID = row['ID']\n        Company_AName = row['Company_AName']\n        Ticker = row['Ticker']\n        Text = row['Text']\n        Call_Section = row['Call_Section']\n        Transcript_Text = row['Transcript_Text']\n        # sentiment = row['sentiment']\n\n        # Perform sentiment analysis on the text to get FinBERT sentiment\n        # input_ids, attention_mask, total_len = text_processing(text)\n        \n        \n        input_ids, attention_mask, total_len = text_processing(Transcript_Text)\n        \n        proba_list = chunk_text_to_window_size_and_predict_proba(input_ids, attention_mask, total_len)\n        mean = get_mean_from_proba(proba_list)\n        result_class = classes[torch.argmax(mean).item()]\n        # print(\"This is the 'proba_list':\",proba_list) # BH Tue 16Apr 20.08\n        # Count of probability classes per line.\n        \n        # Initialize counters\n        count_positive = 0\n        count_negative = 0\n        count_neutral = 0\n        \n        # Count the occurrences of each class\n        for prob in proba_list:\n            pred_class = torch.argmax(prob).item()\n            if pred_class == 0:\n                count_positive += 1\n            elif pred_class == 1:\n                count_negative += 1\n            elif pred_class == 2:\n                count_neutral += 1\n\n        # Write the processed row to the output CSV file\n        csv_writer.writerow([ID, Company_AName, Ticker, Text, Call_Section, Transcript_Text, result_class, count_positive, count_negative, count_neutral]) \n\n        # Write the processed row to the output CSV file\n        # csv_writer.writerow([phrase_id, sentiment, text, result_class])\n        \n        # BH 11Apr2024 15.39:- \n        # Write the processed row to the output CSV file\n        # csv_writer.writerow([ID, Company_AName, Ticker, Text, Call_Section, Transcript_Text, result_class])","metadata":{"execution":{"iopub.status.busy":"2024-07-26T14:41:02.487682Z","iopub.execute_input":"2024-07-26T14:41:02.488061Z","iopub.status.idle":"2024-07-26T14:47:28.980152Z","shell.execute_reply.started":"2024-07-26T14:41:02.488032Z","shell.execute_reply":"2024-07-26T14:47:28.979124Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:836: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\nToken indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}